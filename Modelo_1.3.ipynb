{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso de clasificaci√≥n de comentarios\n",
    "\n",
    "Un procesamiento alternativo al caso anterior para poder obtener la probabilidad de ocurrencia sin necesidad de calcular la clase general (omitir columna binary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 41116: expected 7 fields, saw 11\\nSkipping line 41247: expected 7 fields, saw 11\\nSkipping line 67200: expected 7 fields, saw 11\\nSkipping line 69160: expected 7 fields, saw 11\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>daww he matches this background colour im seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man im really not trying to edit war its j...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>more i cant make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>congratulations from me as well use the tool...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>your vandalism to the matt shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>sorry if the word nonsense was offensive to yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  explanation why the edits made under my userna...      0   \n",
       "1  000103f0d9cfb60f  daww he matches this background colour im seem...      0   \n",
       "2  000113f07ec002fd  hey man im really not trying to edit war its j...      0   \n",
       "3  0001b41b1c6bb37e   more i cant make any real suggestions on impr...      0   \n",
       "4  0001d958c54c6e35  you sir are my hero any chance you remember wh...      0   \n",
       "5  00025465d4725e87    congratulations from me as well use the tool...      0   \n",
       "6  0002bcb3da6cb337       cocksucker before you piss around on my work      1   \n",
       "7  00031b1e95af7921  your vandalism to the matt shirvington article...      0   \n",
       "8  00037261f536c51d  sorry if the word nonsense was offensive to yo...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             1        1       0       1              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, string\n",
    "\n",
    "df_train = pd.read_csv('./train.csv')\n",
    "df_test = pd.read_csv('./comments.csv',encoding='utf-16', sep=',',  error_bad_lines=False)\n",
    "\n",
    "cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "def clean_text_round1(text):\n",
    "    '''make text lowercase, remove punctuation.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('[\\n]', ' ', text)\n",
    "    text = re.sub('@\\w+', '', text)\n",
    "    text = re.sub('rt', '', text)\n",
    "    text = re.sub(\"(http://.*?\\s)|(http://.*)\",'',text)\n",
    "    return text\n",
    "\n",
    "df_train.comment_text = df_train.comment_text.apply(lambda x: clean_text_round1(x))\n",
    "df_test.rename(columns={'comment':'comment_text'}, inplace=True)\n",
    "df_test.comment_text = df_test.comment_text.apply(lambda x: clean_text_round1(x))\n",
    "df_train.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0      0             0        0       0       0              0\n",
       "1      0             0        0       0       0              0\n",
       "2      0             0        0       0       0              0\n",
       "3      0             0        0       0       0              0\n",
       "4      0             0        0       0       0              0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_subset = df_train.loc[:,cols]\n",
    "df_train_text = df_train.loc[:, 'comment_text']\n",
    "df_train_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizar los datos de texto\n",
    "Utilizando un modelo de tf-idf podemos capturar el vocabulario a analizar y poder vectorizarlo de manera num√©rica la configuraci√≥n del tf-idf que utilizamos fue la siguiente:\n",
    "\n",
    "* stop_words: en ingl√©s\n",
    "* sublinear_tf: le asigna un peso a cada token palabra\n",
    "* lowercase: pasar toda la info a min√∫scula\n",
    "* strip_accents: Quita los caracteres de acentuaci√≥n\n",
    "* analyzer: analizamos siempre a nevel de palabras\n",
    "* token pattern: palabras de 2 o mas caracteres\n",
    "* ngram_range: permitir grupos de 1, 2 o 3 palabras\n",
    "* max_features: cantidad m√°ximas de features a capturar 50000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train_text, df_train_subset, test_size= 0.3, random_state=13)\n",
    "\n",
    "# Instantiate the vectorizer\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    sublinear_tf=True,\n",
    "    lowercase = True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{2,}',  #vectorize 2-character words or more\n",
    "    ngram_range=(1, 3), #unigrams and trigrams\n",
    "    max_features=50000)\n",
    "\n",
    "# fit and transform on it the training features\n",
    "word_vectorizer.fit(X_train)\n",
    "X_train_word_features = word_vectorizer.transform(X_train)\n",
    "\n",
    "#transform the test features to sparse matrix\n",
    "test_features = word_vectorizer.transform(X_test)\n",
    "\n",
    "word_features = word_vectorizer.transform(df_test['comment_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with lowest idf:\n",
      "['article' 'page' 'talk' 'wikipedia']\n",
      "\n",
      "Features with highest idf:\n",
      "['faggotjeske couriano' 'faggotjeske couriano stupid' 'faggot gay'\n",
      " 'criminalwar']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(word_vectorizer.get_feature_names())\n",
    "sorted_by_idf = np.argsort(word_vectorizer.idf_)\n",
    "print(\"Features with lowest idf:\\n{}\".format(\n",
    "       feature_names[sorted_by_idf[:4]]))\n",
    "print(\"\\nFeatures with highest idf:\\n{}\".format(\n",
    "       feature_names[sorted_by_idf[-4:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementar modelos\n",
    "\n",
    "En esta secci√≥n se implementan los modelos `Naive Bayes Multinomial` y `Naive Bayes Bernoulli` la literatura recomienda Bernoulli para analizar datos que tienen comportamientos binarios de verdadero o falso, lo cual se ajustan a los datos que presentamos, en un ciclo para clase de comentario t√≥xico entrenamos el modelo, lo exportamos y lo evaluamospara seleccionar el mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report, precision_score\n",
    "import sklearn.metrics as metrics\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "df_classification_report = pd.DataFrame(columns=['Class_Name','Log_loss_MN', 'Accuracy_MN', 'Accuracy_MN_vs_Test','Log_loss_BN', 'Accuracy_BN', 'Accuracy_BN_vs_Test'])\n",
    "losses = []\n",
    "auc = []\n",
    "auctest= []\n",
    "lossesBN = []\n",
    "aucBN = []\n",
    "aucBNtest = []\n",
    "dict_confussion_matrix = {} # TODO ADD ELEMENTS TO DICT\n",
    "\n",
    "\n",
    "for class_name in tqdm(cols):\n",
    "    train_target = y_train[class_name]\n",
    "    test_target  = y_test[class_name]\n",
    "    \n",
    "    #modelo multinomial naive bayes\n",
    "    clf = MultinomialNB()\n",
    "    \n",
    "    cv_loss = np.mean(cross_val_score(clf, X_train_word_features, train_target,  cv=3, scoring='neg_log_loss'))\n",
    "    losses.append(cv_loss)\n",
    "    clf.fit(X_train_word_features, train_target)\n",
    "    \n",
    "    cv_score = precision_score(train_target, clf.predict(X_train_word_features))\n",
    "    auc.append(cv_score)\n",
    "    \n",
    "    y_pred = clf.predict(test_features)\n",
    "    y_pred_prob = clf.predict_proba(test_features)[:, 1]\n",
    "    auc_score = metrics.roc_auc_score(test_target, y_pred)\n",
    "    auctest.append(auc_score) \n",
    "    \n",
    "    # TODO EXPORT CLASSIFIER AS PICKLE OBJECT ALSO THE TFIDF\n",
    "    pickle.dump( clf, open( \"multinomial_\"+class_name+\".pkl\", \"wb\" ) )\n",
    "    #plot confusion matrix\n",
    "    confusion_matrix(test_target, y_pred)\n",
    "    \n",
    "    #modelo bayes bernoulli teoricamente trabaja mejor con variables binarias\n",
    "    clf2 = BernoulliNB()\n",
    "    cv_loss = np.mean(cross_val_score(clf2, X_train_word_features, train_target, cv=3, scoring='neg_log_loss'))\n",
    "    lossesBN.append(cv_loss)\n",
    "    clf2.fit(X_train_word_features, train_target)\n",
    "    \n",
    "    cv_score = precision_score(train_target, clf2.predict(X_train_word_features))\n",
    "    aucBN.append(cv_score)\n",
    "    y_pred = clf2.predict(test_features)\n",
    "    y_pred_prob = clf2.predict_proba(test_features)[:, 1]\n",
    "    auc_score = metrics.roc_auc_score(test_target, y_pred)\n",
    "    aucBNtest.append(auc_score)\n",
    "    pickle.dump( clf2, open( \"bernoulli_\"+class_name+\".pkl\", \"wb\" ) )\n",
    "\n",
    "df_classification_report['Class_Name'] = cols\n",
    "df_classification_report['Log_loss_MN'] = losses\n",
    "df_classification_report['Accuracy_MN'] = auc\n",
    "df_classification_report['Accuracy_MN_vs_Test'] = auctest\n",
    "df_classification_report['Log_loss_BN'] = lossesBN\n",
    "df_classification_report['Accuracy_BN'] = aucBN\n",
    "df_classification_report['Accuracy_BN_vs_Test'] = aucBNtest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class_Name</th>\n",
       "      <th>Log_loss_MN</th>\n",
       "      <th>Accuracy_MN</th>\n",
       "      <th>Accuracy_MN_vs_Test</th>\n",
       "      <th>Log_loss_BN</th>\n",
       "      <th>Accuracy_BN</th>\n",
       "      <th>Accuracy_BN_vs_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic</td>\n",
       "      <td>-0.177276</td>\n",
       "      <td>0.948737</td>\n",
       "      <td>0.700372</td>\n",
       "      <td>-1.287204</td>\n",
       "      <td>0.211122</td>\n",
       "      <td>0.765914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>-0.050690</td>\n",
       "      <td>0.420455</td>\n",
       "      <td>0.507131</td>\n",
       "      <td>-0.451709</td>\n",
       "      <td>0.276540</td>\n",
       "      <td>0.548347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>-0.122314</td>\n",
       "      <td>0.901398</td>\n",
       "      <td>0.680530</td>\n",
       "      <td>-0.333266</td>\n",
       "      <td>0.187398</td>\n",
       "      <td>0.836873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>-0.025641</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.506554</td>\n",
       "      <td>-0.416821</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.500865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>-0.131988</td>\n",
       "      <td>0.830539</td>\n",
       "      <td>0.630679</td>\n",
       "      <td>-0.344520</td>\n",
       "      <td>0.182151</td>\n",
       "      <td>0.833506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>-0.056889</td>\n",
       "      <td>0.186275</td>\n",
       "      <td>0.500863</td>\n",
       "      <td>-0.566038</td>\n",
       "      <td>0.109932</td>\n",
       "      <td>0.520863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class_Name  Log_loss_MN  Accuracy_MN  Accuracy_MN_vs_Test  Log_loss_BN  \\\n",
       "0          toxic    -0.177276     0.948737             0.700372    -1.287204   \n",
       "1   severe_toxic    -0.050690     0.420455             0.507131    -0.451709   \n",
       "2        obscene    -0.122314     0.901398             0.680530    -0.333266   \n",
       "3         threat    -0.025641     0.086207             0.506554    -0.416821   \n",
       "4         insult    -0.131988     0.830539             0.630679    -0.344520   \n",
       "5  identity_hate    -0.056889     0.186275             0.500863    -0.566038   \n",
       "\n",
       "   Accuracy_BN  Accuracy_BN_vs_Test  \n",
       "0     0.211122             0.765914  \n",
       "1     0.276540             0.548347  \n",
       "2     0.187398             0.836873  \n",
       "3     0.004228             0.500865  \n",
       "4     0.182151             0.833506  \n",
       "5     0.109932             0.520863  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 25.60it/s]\n"
     ]
    }
   ],
   "source": [
    "submission_multinomial_nb = pd.DataFrame.from_dict({'id': df_test['id']}) #DATAFRAME DE SALIDA\n",
    "submission_bernoulli_nb = pd.DataFrame.from_dict({'id': df_test['id']}) #DATAFRAME DE SALIDA\n",
    "for class_name in tqdm(cols):\n",
    "    clf  = pickle.load( open( \"multinomial_\"+class_name+\".pkl\", \"rb\" ) )\n",
    "    clf2 = pickle.load( open( \"bernoulli_\" +class_name+\".pkl\", \"rb\" ) )\n",
    "    \n",
    "    y_pred_prob = clf.predict_proba(word_features)[:, 1]\n",
    "    submission_multinomial_nb[class_name] = y_pred_prob\n",
    "    \n",
    "    y_pred_prob = clf2.predict_proba(word_features)[:, 1]\n",
    "    submission_bernoulli_nb[class_name] = y_pred_prob\n",
    "    \n",
    "submission_multinomial_nb = pd.merge(submission_multinomial_nb, df_test, on='id')\n",
    "submission_bernoulli_nb = pd.merge(submission_bernoulli_nb, df_test, on='id')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportar resultados\n",
    "Esta secci√≥n se encarga de analizar y exportar los resultados de los dataframes de salida al bucket en s3, se observa que los resultados de ernoulli tienen a ser mas extremos o muy cercanos a cero o muy cercanos a 1 pero no existen valores intermedios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>source</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.105708</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.041888</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.042474</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>rt nosurrenderhk guardiannews the truth is hk ...</td>\n",
       "      <td>2020-06-13 16:07:02</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>1271836487663808513</td>\n",
       "      <td>currentecalamo</td>\n",
       "      <td>1005852785609326592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.036546</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.011103</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>rt marisakabas content warning police brutalit...</td>\n",
       "      <td>2020-06-13 16:07:02</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>1271836487663775744</td>\n",
       "      <td>Donald Dire</td>\n",
       "      <td>1088300096666591232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.295848</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.045820</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.044702</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>rt shahmiruk it is absolutely unfair amp disin...</td>\n",
       "      <td>2020-06-13 16:07:02</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1271836487693275144</td>\n",
       "      <td>tanya cochrane üï∑#FBPE</td>\n",
       "      <td>25872176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.065238</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.024562</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.022834</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>rt autotheoryqueen terfs police the boundaries...</td>\n",
       "      <td>2020-06-13 16:07:02</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1271836487747862529</td>\n",
       "      <td>Michael Bermingham</td>\n",
       "      <td>59031350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.115526</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.023836</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>looks like a scary demon witch monster to me</td>\n",
       "      <td>2020-06-13 16:07:02</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1271836487676579841</td>\n",
       "      <td>untossable chum</td>\n",
       "      <td>2771192143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     toxic  severe_toxic   obscene    threat    insult  identity_hate  \\\n",
       "0   0  0.105708      0.004472  0.041888  0.001209  0.042474       0.004801   \n",
       "1   1  0.036546      0.000580  0.011783  0.000135  0.011103       0.000622   \n",
       "2   2  0.295848      0.000986  0.045820  0.000123  0.044702       0.001886   \n",
       "3   3  0.065238      0.002006  0.024562  0.000536  0.022834       0.003012   \n",
       "4   4  0.115526      0.001275  0.023836  0.000428  0.020619       0.001658   \n",
       "\n",
       "                                        comment_text        creation_time  \\\n",
       "0  rt nosurrenderhk guardiannews the truth is hk ...  2020-06-13 16:07:02   \n",
       "1  rt marisakabas content warning police brutalit...  2020-06-13 16:07:02   \n",
       "2  rt shahmiruk it is absolutely unfair amp disin...  2020-06-13 16:07:02   \n",
       "3  rt autotheoryqueen terfs police the boundaries...  2020-06-13 16:07:02   \n",
       "4       looks like a scary demon witch monster to me  2020-06-13 16:07:02   \n",
       "\n",
       "                source             tweet_id                   user  \\\n",
       "0  Twitter for Android  1271836487663808513         currentecalamo   \n",
       "1  Twitter for Android  1271836487663775744            Donald Dire   \n",
       "2   Twitter for iPhone  1271836487693275144  tanya cochrane üï∑#FBPE   \n",
       "3   Twitter for iPhone  1271836487747862529     Michael Bermingham   \n",
       "4   Twitter for iPhone  1271836487676579841        untossable chum   \n",
       "\n",
       "               user_id  \n",
       "0  1005852785609326592  \n",
       "1  1088300096666591232  \n",
       "2             25872176  \n",
       "3             59031350  \n",
       "4           2771192143  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_multinomial_nb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>source</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.997282</td>\n",
       "      <td>1.092819e-12</td>\n",
       "      <td>0.779152</td>\n",
       "      <td>1.607791e-56</td>\n",
       "      <td>0.853161</td>\n",
       "      <td>3.243856e-15</td>\n",
       "      <td>rt nosurrenderhk guardiannews the truth is hk ...</td>\n",
       "      <td>2020-06-13 16:07:02</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>1271836487663808513</td>\n",
       "      <td>currentecalamo</td>\n",
       "      <td>1005852785609326592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.427635</td>\n",
       "      <td>4.902138e-15</td>\n",
       "      <td>0.018746</td>\n",
       "      <td>1.567621e-56</td>\n",
       "      <td>0.040786</td>\n",
       "      <td>8.615133e-17</td>\n",
       "      <td>rt marisakabas content warning police brutalit...</td>\n",
       "      <td>2020-06-13 16:07:02</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>1271836487663775744</td>\n",
       "      <td>Donald Dire</td>\n",
       "      <td>1088300096666591232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>5.829787e-13</td>\n",
       "      <td>0.994642</td>\n",
       "      <td>6.330744e-57</td>\n",
       "      <td>0.994836</td>\n",
       "      <td>7.841235e-14</td>\n",
       "      <td>rt shahmiruk it is absolutely unfair amp disin...</td>\n",
       "      <td>2020-06-13 16:07:02</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1271836487693275144</td>\n",
       "      <td>tanya cochrane üï∑#FBPE</td>\n",
       "      <td>25872176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.994582</td>\n",
       "      <td>2.830223e-14</td>\n",
       "      <td>0.756531</td>\n",
       "      <td>7.192166e-60</td>\n",
       "      <td>0.779185</td>\n",
       "      <td>2.081745e-16</td>\n",
       "      <td>rt autotheoryqueen terfs police the boundaries...</td>\n",
       "      <td>2020-06-13 16:07:02</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1271836487747862529</td>\n",
       "      <td>Michael Bermingham</td>\n",
       "      <td>59031350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.999635</td>\n",
       "      <td>1.908485e-14</td>\n",
       "      <td>0.920415</td>\n",
       "      <td>3.875811e-59</td>\n",
       "      <td>0.958583</td>\n",
       "      <td>9.044567e-17</td>\n",
       "      <td>looks like a scary demon witch monster to me</td>\n",
       "      <td>2020-06-13 16:07:02</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1271836487676579841</td>\n",
       "      <td>untossable chum</td>\n",
       "      <td>2771192143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     toxic  severe_toxic   obscene        threat    insult  \\\n",
       "0   0  0.997282  1.092819e-12  0.779152  1.607791e-56  0.853161   \n",
       "1   1  0.427635  4.902138e-15  0.018746  1.567621e-56  0.040786   \n",
       "2   2  0.999996  5.829787e-13  0.994642  6.330744e-57  0.994836   \n",
       "3   3  0.994582  2.830223e-14  0.756531  7.192166e-60  0.779185   \n",
       "4   4  0.999635  1.908485e-14  0.920415  3.875811e-59  0.958583   \n",
       "\n",
       "   identity_hate                                       comment_text  \\\n",
       "0   3.243856e-15  rt nosurrenderhk guardiannews the truth is hk ...   \n",
       "1   8.615133e-17  rt marisakabas content warning police brutalit...   \n",
       "2   7.841235e-14  rt shahmiruk it is absolutely unfair amp disin...   \n",
       "3   2.081745e-16  rt autotheoryqueen terfs police the boundaries...   \n",
       "4   9.044567e-17       looks like a scary demon witch monster to me   \n",
       "\n",
       "         creation_time               source             tweet_id  \\\n",
       "0  2020-06-13 16:07:02  Twitter for Android  1271836487663808513   \n",
       "1  2020-06-13 16:07:02  Twitter for Android  1271836487663775744   \n",
       "2  2020-06-13 16:07:02   Twitter for iPhone  1271836487693275144   \n",
       "3  2020-06-13 16:07:02   Twitter for iPhone  1271836487747862529   \n",
       "4  2020-06-13 16:07:02   Twitter for iPhone  1271836487676579841   \n",
       "\n",
       "                    user              user_id  \n",
       "0         currentecalamo  1005852785609326592  \n",
       "1            Donald Dire  1088300096666591232  \n",
       "2  tanya cochrane üï∑#FBPE             25872176  \n",
       "3     Michael Bermingham             59031350  \n",
       "4        untossable chum           2771192143  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_bernoulli_nb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
